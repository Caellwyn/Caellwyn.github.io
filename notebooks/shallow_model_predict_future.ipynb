{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the right model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join(os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from src.functions import load_OU_data, CourseScaler, plot_confusion, score_grid, \\\n",
    "smotecourses, process_courses, course_cross_validate, Course_GridSearchCV\n",
    "\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set_style('white')\n",
    "pd.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop the Irrelevant Columns\n",
    "We are hoping to predict student success by using only data that can be collected anonymously by the online learning platform itself based directly on student behavior, so we need to drop data that those services might not have.  Our dataset includes demographic data such as gender, disability, age, and socio-economics, but we will not use those for prediction.  In our EDA, we found that demographic data was not strongly correlated to course outcomes anyway.\n",
    "\n",
    "## Set Prediction Window to .5\n",
    "We want to make timely predictions to intervene with students in time to help them succeed, so we will only use data from the first half of the shortest course.  This approach is a compromise.  By only using part of the data we are handicapping our model in its ability to make predictions.  On the other hand we are able to produce a prediction to red-flag students before the end of the course so instructors or the system can intervene.\n",
    "\n",
    "By halfway through the course we've lost about half of the student who would eventually withdraw, but if we set our prediction window earlier, our model loses accuracy and still misses those students and the ones who will fail.  It also recommends more interventions for students who don't need them.  The halfway point seems like a reasonable compromise, but the function that loads the data allows this window to be changed if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "We will separate our target variable from the predictor variables into X and y variables respectively, and then divide the dataset into 4 subgroups to be used to validate the accuracy of our model on new data, train and test, which will be used to validate our final model, and 't' (an intermediate training test) and 'val' which will be used to evaluate model candidates along the way.  When we use cross-validation the 't' set will be further divided.  While this gives our models less data to train on, it maximizes our ability to ensure that validity of our models and identify any overfitting.\n",
    "\n",
    "## Collapse targets\n",
    "This dataset divides outcomes into four categories: 'Distinction','Pass','Fail','Withdrawn'.  We want to separate students into \"Needs Intervention\" and \"Does Not Need Intervention.\"  To that end, we will combine targets in the target variable.  'Distinction' and 'Pass' will both become \"No Intervention\" and \"Fail\" and \"Withdrawn\" will become \"Needs Intervention.\"  This improves model accuracy as well as creating more clear metrics and a simpler recommender system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_OU_data(prediction_window=.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[df['code_presentation'].isin(['2013B','2013J','2014B'])]\n",
    "test = df[df['code_presentation'] == '2014J']\n",
    "train_modules = train['code_module'].unique()\n",
    "test = test[test['code_module'].isin(train_modules)]\n",
    "\n",
    "X_train = train.drop(columns = ['id_student','code_presentation','region','highest_education', \\\n",
    "                   'imd_band','gender','age_band','disability','studied_credits',\n",
    "                   'module_presentation_length','date_registration','final_result'])\n",
    "X_test = test.drop(columns = ['id_student','code_presentation','region','highest_education', \\\n",
    "                   'imd_band','gender','age_band','disability','studied_credits',\n",
    "                   'module_presentation_length','date_registration','final_result'])\n",
    "y_train = np.array(['No Intervention' if w in ['Pass','Distinction'] \\\n",
    "              else 'Needs Intervention' for w in train['final_result']])\n",
    "y_test = np.array(['No Intervention' if w in ['Pass','Distinction'] \\\n",
    "              else 'Needs Intervention' for w in test['final_result']])\n",
    "\n",
    "cv = KFold(n_splits = 5, shuffle = True, random_state = 111)\n",
    "\n",
    "df_t = df[df['code_presentation'].isin(['2013B','2013J'])]\n",
    "df_val = df[df['code_presentation'] == '2014B']\n",
    "df_t_modules = df_t['code_module'].unique()\n",
    "df_val = df_val[df_val['code_module'].isin(df_t_modules)]\n",
    "\n",
    "X_t = df_t.drop(columns = ['id_student','code_presentation','region','highest_education', \\\n",
    "                   'imd_band','gender','age_band','disability','studied_credits',\n",
    "                   'module_presentation_length','date_registration','final_result'])\n",
    "X_val = df_val.drop(columns = ['id_student','code_presentation','region','highest_education', \\\n",
    "                   'imd_band','gender','age_band','disability','studied_credits',\n",
    "                   'module_presentation_length','date_registration','final_result'])\n",
    "y_t = np.array(['No Intervention' if w in ['Pass','Distinction'] \\\n",
    "              else 'Needs Intervention' for w in df_t['final_result']])\n",
    "y_val = np.array(['No Intervention' if w in ['Pass','Distinction'] \\\n",
    "              else 'Needs Intervention' for w in df_val['final_result']])\n",
    "\n",
    "X_train_modules = X_train['code_module'].unique()\n",
    "X_test = X_test[X_test['code_module'].isin(X_train_modules)]\n",
    "\n",
    "\n",
    "\n",
    "transformed_big_data = process_courses(X_train, y_train, X_test, y_test)\n",
    "X_train_transformed, y_train_transformed, X_test_transformed, y_test = transformed_big_data\n",
    "transformed_little_data = process_courses(X_t, y_t, X_val, y_val)\n",
    "X_t_transformed, y_t_transformed, X_val_transformed, y_val = transformed_little_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4450 entries, 3706 to 23206\n",
      "Data columns (total 6 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   num_of_prev_attempts      4450 non-null   float64\n",
      " 1   days_studied              4450 non-null   float64\n",
      " 2   activities_engaged        4450 non-null   float64\n",
      " 3   total_clicks              4450 non-null   float64\n",
      " 4   assessments_completed     4450 non-null   float64\n",
      " 5   average_assessment_score  4450 non-null   float64\n",
      "dtypes: float64(6)\n",
      "memory usage: 243.4 KB\n"
     ]
    }
   ],
   "source": [
    "X_val_transformed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4450"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CourseScaler class and smotecourses() function\n",
    "We run into a problem with our data because this dataset comprises 7 different courses and each course has different numbers of activities, assessments, and demands different amounts of work.  This creates a variable in the data which is unrelated to the actual student activity or effort, but is intrinsic in the course itself.  We can partially over come this, making our model more general, by normalizing the activity statistics for each course.  In other words, while 100 activities may be sufficient to succeed in course A, 200 activities may be necessary for course B.  Instead, we take the mean of all students' activitiy counts and divide by the standard deviation.  Now the necessary activities for course A and B are set to the same value, more or less.  \n",
    "\n",
    "This is what the `CourseScaler` transformer does. It can fit on and transform the training data and then use the mean and standard deviation from the training data to transform the test data on the same scale.\n",
    "\n",
    "But, different courses don't also have different work requirements, they also have different success rates, which will also bias the predictions.  The solution is to balance the classes in each course to remove this bias as well, which is what the function `smotecourses()` does.  SMOTE is a class from [Imbalanced Learn](https://imbalanced-learn.org/stable/index.html) which creates synthetic data as a way of upsampling a minority class without directly duplicating observations.  It uses a K-neartest neighbors approach to create new observations with very similar features to others.  Once the minority class is smoted, the classes are balanced in each course and the bias is removed.  For the purposes of training our model, each course has the same graduation rate and requires the same level of effort and grades assessments on the same scale.  See the readme for a more on why this is important.\n",
    "\n",
    "I wrap these into the `process_courses()` function, which returns scaled and smoted training set and a test set scaled on the CourseScaler fitted on the train set (but not smoted)\n",
    "\n",
    "With these solutions we can overcome the bias that different courses would have otherwise introduced into our dataset.\n",
    "\n",
    "# When do we transform?\n",
    "We are going to create transformed versions of the above datasets for use in evaluating models.  However our custom course_cross_validate function will automatically perform these transformations on each cross-validation fold during it's hyperparameter search to prevent data leakage during cross validation.  When we cross-validate models we will only give them the X_t and y_t datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FSM\n",
    "A decent start for a baseline model, a logistic regresson model seeks the best fit line to model the linear relationship between the predictor variables, X, and the target variable, y, which is a linear regression. It then applies a sigmoid function to that line to assign probabilities that each observation belongs in one class or the other.  For our purposes, if the probability of an observation belonging a class is greater than .5, then we will predict that it belongs to that class.  We will use our custom cross_validate function to remove the course bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7724637681159421, 0.7830917874396135, 0.7864734299516908, 0.7805703238279362, 0.7849202513291446]\n",
      "Mean cross validated accuracy:\n",
      "0.7815039121328654\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'AAA'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-a4befceb3551>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Mean cross validated accuracy:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val_transformed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'validation accuracy: '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\new_Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1340\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1342\u001b[1;33m         X, y = self._validate_data(X, y, accept_sparse='csr', dtype=_dtype,\n\u001b[0m\u001b[0;32m   1343\u001b[0m                                    \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"C\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1344\u001b[0m                                    accept_large_sparse=solver != 'liblinear')\n",
      "\u001b[1;32m~\\new_Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\new_Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\new_Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    794\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 796\u001b[1;33m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[0;32m    797\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    798\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\new_Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\new_Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    597\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\new_Anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\new_Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1780\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1781\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1782\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1783\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array_wrap__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\new_Anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'AAA'"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "scores = course_cross_validate(lr,X_t,y_t,scoring='accuracy', cv=cv, random_state = 111)\n",
    "\n",
    "print(scores)\n",
    "print('Mean cross validated accuracy:')\n",
    "print(np.mean(scores))\n",
    "lr.fit(X_t, y_t)\n",
    "y_pred = lr.predict(X_val_transformed)\n",
    "print('validation accuracy: ')\n",
    "print(accuracy_score(y_val, y_pred))\n",
    "plot_confusion(y_val, y_pred, cmap='Greens', save_path='../figures/FSMconfusionmatrix.png')\n",
    "pickle.dump(lr,open('../models/FSM2.pkl','wb'))\n",
    "print(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "The FSM achieves 73.6% accuracy with a good balance between course predictions.  This is a lovely start, but let's see if we can do better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridsearchCV for best logistic regression hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LRparams = [{'solver': ['lbfgs','sag','saga','newton-cg'],\n",
    "         'penalty': ['none'],\n",
    "         'random_state':[111]},\n",
    "          {'solver': ['lbfgs','sag','saga','newton-cg','liblinear'],\n",
    "         'penalty': ['l2'],\n",
    "         'random_state':[111]},\n",
    "          {'solver':['saga'],\n",
    "          'penalty':['elasticnet'], 'l1_ratio':[.1,.5,.7]},\n",
    "          {'solver':['saga','liblinear'],\n",
    "          'penalty':['l1']}]\n",
    "\n",
    "\n",
    "LRgrid = Course_GridSearchCV(LogisticRegression(), LRparams, cv=cv, \n",
    "                                scoring='accuracy', verbose = False)\n",
    "\n",
    "LRgrid.fit(X_t, y_t)\n",
    "LRmodel = score_grid(LRgrid, X_val_transformed, y_val)\n",
    "pickle.dump(LRmodel,open('../models/LRmodel2.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Evaluation\n",
    "By optimizing the hyperparameters of the logistic regression model, which are all regularization parameters, we've barely moved the needle at all.  We gained .0002 accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More model types\n",
    "We used the logistic regression classifier to tune our features, but now it's time to try some other models.  We will use Course_GridsearchCV to optimize the hyperparameters for these as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "A decision tree is a promising candidate for this problem because it does not assume the independence of the features. Instead it seeks to find the best way to divide and subdivide the data in a tree structure based on the values of different variables.  We can tune how many features each split is allowed to consider.  Once the tree is build predictions are made by sending an observations down the tree sending it on a path to the predicted class as it reaches each split in the tree is sent in one or the other direction.  You can think of it like a deterministic Pachinko machine!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTparams = {'criterion':['gini','entropy'],\n",
    "           'splitter':['best','random'],\n",
    "           'max_depth':[4,10],'min_samples_split':[.01,.1,.2,.5],\n",
    "           'max_features':[1,2,3,4,5],'random_state':[111]}\n",
    "           \n",
    "DTgrid = Course_GridSearchCV(DecisionTreeClassifier(), DTparams, cv=cv, scoring = 'accuracy')\n",
    "\n",
    "DTgrid.fit(X_t, y_t)\n",
    "\n",
    "DTmodel = score_grid(DTgrid, X_val_transformed, y_val, cmap = 'Greens')\n",
    "plt.savefig('../figures/DTconfmatrix.png',dpi=250)\n",
    "pickle.dump(DTmodel,open('../models/DTmodel2.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Evaluation \n",
    "As expected, this model is better at predicting how a student will do.  It doesn't rely on establishing a straight line through the data to model it, which is probably not the best approach in this problem space.  We see a nice increase in accuracy here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier\n",
    "This is an interesting extension to the decision tree model.  It creates a whole forest of decision trees and trains each one on a subset of the data and a subset of the features.  This is a technique called bagging, or [Boostrap AGGregation](https://machinelearningmastery.com/bagging-and-random-forest-ensemble-algorithms-for-machine-learning/) (check the link for more on this).  It works on the principle that a bunch of bad predictors, on average will be more accurate than one good predictor.  This worked for Francis Galton in [guessing the weight of an ox](https://crowdsourcingweek.com/blog/using-the-crowd-to-predict/), maybe it will work here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFparams = {'n_estimators':[10,100,150],\n",
    "           'criterion':['gini','entropy'],\n",
    "           'max_depth':[4],\n",
    "           'min_samples_split':[2,4,5],\n",
    "           'oob_score':[True,False],\n",
    "           'n_jobs':[-1],'random_state':[111],\n",
    "           'max_samples':[.5,.7,None]}\n",
    "           \n",
    "RFgrid = Course_GridSearchCV(RandomForestClassifier(), RFparams, cv=cv)\n",
    "\n",
    "RFgrid.fit(X_t, y_t)\n",
    "\n",
    "RFmodel = score_grid(RFgrid, X_val_transformed, y_val, save_path = '../figures/RFmodel2confmatrix.png')\n",
    "pickle.dump(RFmodel, open('../models/RFmodel2.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier Evaluation:\n",
    "Apparently bagging is not the right approach to this problem.  Our single well tuned decision tree outperformed the random forest classifier.  I guess the wisdom of the crowd is not always superior to the wisdom of the expert!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eXtreme Gradient Boost model:\n",
    "XGBoost models have gained a lot of popularity recently and won a lot of Kaggle competitions.  It uses another popular idea called [boosting](https://en.wikipedia.org/wiki/Gradient_boosting).  That's a pretty involved wikipedia article, but the TLDR is that it's a similar ensemble method like random forest, but whereas random forest trains a bunch of trees in parallel and takes the aggregate of their predictions, boosting stacks the trees on top of each other and each one tries to improve on the one below it by predicting where the previous one made mistakes.  I think of it as like a line of morons each grading the next one's paper, which is an analysis of the previous one's paper.  Each one gets a lot wrong, but something right so the right answers percolate through and some of the wrong answers get corrected at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBparams = {'n_estimators':[150,200],\n",
    "             'max_depth':[4],\n",
    "             'learning_rate':[.1], \n",
    "             'subsample':[.7],\n",
    "             'gamma':[0,1],\n",
    "             'min_child_weight':[1,2],\n",
    "             'num_parallel_tree':[1,2],\n",
    "             'eval_metric':['error','logloss'],\n",
    "            'colsample_bytree':[.6,.7,.8],\n",
    "            'base_score':[.1,.2,.4]}\n",
    "           \n",
    "XBGgrid = Course_GridSearchCV(XGBClassifier(objective='binary:logistic', n_jobs=-1, random_state=111),\n",
    "                         XGBparams, cv=cv)\n",
    "XBGgrid.fit(X_t, y_t)\n",
    "\n",
    "XGBmodel = score_grid(XBGgrid, X_val_transformed, y_val, \n",
    "                     save_path = '../figures/XGBmodelconfmatrix4.png')\n",
    "pickle.dump(XGBmodel, open('../models/XGBmodel4.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost evaluation:\n",
    "XGBoost gave us the best cross-validated score of these four model types.  While it performs slightly worse on the validation set than the random forest, looking at the scores across folds, it seems likely that this represents the validation set being a sort of bad split.  XGBoost also performs equally well on both classes.  It correctly identifies 74% of students who need intervention to succeed, while misclassifying 27% of passing students as needing intervention.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM\n",
    "An SVM, or support vector machine, attempts to draw a line, or hyperplane, between the classes to divide them.  This can be degree 2 polynomial line or higher, creating curved dividers of different shapes to match more complex decision boundaries.  It finds the best fit such hyperplane so as to maximize the distance between observations in a recursive manner.  EDA suggests that the observations can, to a large extent, be divided along the variables we have seen.  Decision trees, which do not operate this way, have been relatively successful, but let's see what this model, somewhat more closely related to the logistic regression, can do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVCparams = {'C':[.01],\n",
    "            'kernel':['linear',],\n",
    "             'gamma':['auto'],\n",
    "             'tol':[1e-3],}\n",
    "             \n",
    "SVCgrid = Course_GridSearchCV(SVC(random_state=111), SVCparams, cv=cv, \n",
    "                                scoring='accuracy', verbose = True)\n",
    "\n",
    "SVCgrid.fit(X_t, y_t)\n",
    "SVCmodel = score_grid(SVCgrid, X_val_transformed, y_val)\n",
    "pickle.dump(SVCmodel, open('../models/SVCmodel1.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Evaluation\n",
    "The SVM performed quite well.  It scored an overall accuracy of 77% with slight prediction bias toward 'No Intervention', in line with the other models.  \n",
    "\n",
    "Different hyper parameters didn't make much difference to accuracy, except a polynomial kernel (degree 3) over predicted student success.  This would be the way to go if interventions are particularly costly.  If you biased the predictions that much toward 'No Intervention', you could be fairly certain that the students receiving interventions really need them.  The same results could also be achieved with the logistic regression model by setting the decision point of the sigmoid function toward the passing class, biasing the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors\n",
    "This model positions each observation (student registration in this case) from the training set in n_feature dimensional space.  New observations from the test set are voted on by the closest K observations from the training set to determine which class the new observation should belong to. There are two big benefits to this modeling technique for our dataset.  The first is that it is fast with few features.  We have only 6 features, so the dimensionality of the space is low, observations are more tightly packed, and the model makes determinations quickly.  The second benefit is that it is non-linear.  We've had some success with more linear models, and decision tree models.  Our error analysis and EDA show that there are strong linear relationships between our variables and the success of students.  However there is a solid 20% of students that cannot seem to be classified with these linear models.  The decision tree models similar seem to fail to classify these students.  Perhaps this model can help find where they belong.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNNparams = {'n_neighbors':[30, 50, 100, 150],\n",
    "            'weights':['distance'],\n",
    "             'p':[6, 7, 8, 9],\n",
    "             'n_jobs':[-1],}\n",
    "             \n",
    "KNNgrid = Course_GridSearchCV(KNeighborsClassifier(), KNNparams, cv=cv, \n",
    "                                scoring='accuracy', verbose = False)\n",
    "\n",
    "KNNgrid.fit(X_t, y_t)\n",
    "KNNmodel = score_grid(KNNgrid, X_val_transformed, y_val)\n",
    "pickle.dump(KNNmodel, open('../models/KNNmodel1.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Evaluation\n",
    "This model, like the others, seems to top out around 77%.  We still haven't found a way to capture the pattern for how those last 20-23% of students fail or withdraw.  Looking at our error analysis from the final report notebook we see that those misclassfied students really look a lot like successful ones according to all of our variables.  It may just be that we don't have the right variable to find the connection.  We may be running up against the irreducible error for this feature set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model:\n",
    "Our XGboost model performed the best here, so lets give it the whole training set to learn from and see how it does on our hold-out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = pickle.load(open('../models/XGBmodel4.pkl','rb'))\n",
    "\n",
    "final_model.fit(X_train_transformed, y_train_transformed)\n",
    "y_pred = final_model.predict(X_test_transformed)\n",
    "print('Final Model')\n",
    "print(final_model)\n",
    "print('Final Model Classification Report')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('Final Model Confusion Matrix')\n",
    "plot_confusion(y_test, y_pred, save_path='../figures/final_modelconfmatrix.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model Evaluation:\n",
    "Our final model, the XGBoost, does pretty well on the test set.  We could have hoped for more, but this is pretty good.  It identifies almost 80% of students in danger of who will do fine while misclassifying a little more than a quarter of students needing interventions.  This may not be ready for deployment, but I believe it serves as a solid proof of concept that student success can be, in many cases, predicted by their interactions with a virtual learning environment.  The difference in different models was, for the most part, quite small.  The XGBoost only won out by 2% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFmodel.fit(X_train_transformed,y_train_transformed)\n",
    "y_pred = RFmodel.predict(X_test_transformed)\n",
    "plot_confusion(y_test, y_pred)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTmodel.fit(X_train_transformed,y_train_transformed)\n",
    "y_pred = DTmodel.predict(X_test_transformed)\n",
    "plot_confusion(y_test, y_pred)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LRmodel.fit(X_train_transformed,y_train_transformed)\n",
    "y_pred = LRmodel.predict(X_test_transformed)\n",
    "plot_confusion(y_test, y_pred)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVCmodel.fit(X_train_transformed,y_train_transformed)\n",
    "y_pred = SVCmodel.predict(X_test_transformed)\n",
    "plot_confusion(y_test, y_pred)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBmodel.fit(X_train_transformed,y_train_transformed)\n",
    "y_pred = XGBmodel.predict(X_test_transformed)\n",
    "plot_confusion(y_test, y_pred)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNNmodel.fit(X_train_transformed,y_train_transformed)\n",
    "y_pred = KNNmodel.predict(X_test_transformed)\n",
    "plot_confusion(y_test, y_pred)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
